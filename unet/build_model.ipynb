{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional, Tuple, Union, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from module import Module\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torch.optim.lr_scheduler import MultiplicativeLR, LambdaLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, n_channels: int):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.lin1 = nn.Linear(self.n_channels // 4, self.n_channels)\n",
    "        self.act = Swish()\n",
    "        self.lin2 = nn.Linear(self.n_channels, self.n_channels)\n",
    "\n",
    "    def forward(self, t: torch.Tensor):\n",
    "        half_dim = self.n_channels // 8\n",
    "        emb = math.log(10_000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
    "        emb = self.act(self.lin1(emb))\n",
    "        emb = self.lin2(emb)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, time_channels: int, n_groups: int = 32, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.GroupNorm(n_groups, in_channels)\n",
    "        self.act1 = Swish()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.norm2 = nn.GroupNorm(n_groups, out_channels)\n",
    "        self.act2 = Swish()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1)) if in_channels != out_channels else nn.Identity()\n",
    "        self.time_emb = nn.Linear(time_channels, out_channels)\n",
    "        self.time_act = Swish()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        h = self.conv1(self.act1(self.norm1(x)))\n",
    "        h += self.time_emb(self.time_act(t))[:, :, None, None]\n",
    "        h = self.conv2(self.dropout(self.act2(self.norm2(h))))\n",
    "        return h + self.shortcut(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(Module):\n",
    "    def __init__(self, n_channels: int, n_heads: int = 1, d_k: int = None, n_groups: int = 32):\n",
    "        super().__init__()\n",
    "        d_k = d_k if d_k is not None else n_channels\n",
    "        self.norm = nn.GroupNorm(n_groups, n_channels)\n",
    "        self.projection = nn.Linear(n_channels, n_heads * d_k * 3)\n",
    "        self.output = nn.Linear(n_heads * d_k, n_channels)\n",
    "        self.scale = d_k ** -0.5\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: Optional[torch.Tensor] = None):\n",
    "        _ = t\n",
    "        batch_size, n_channels, height, width = x.shape\n",
    "        x = x.view(batch_size, n_channels, -1).permute(0, 2, 1)\n",
    "        qkv = self.projection(x).view(batch_size, -1, self.n_heads, 3 * self.d_k)\n",
    "        q, k, v = torch.chunk(qkv, 3, dim=-1)\n",
    "        attn = torch.einsum('bihd,bjhd->bijh', q, k) * self.scale\n",
    "        attn = attn.softmax(dim=2)\n",
    "        res = torch.einsum('bijh,bjhd->bihd', attn, v)\n",
    "        res = res.view(batch_size, -1, self.n_heads * self.d_k)\n",
    "        res = self.output(res)\n",
    "        res += x\n",
    "        res = res.permute(0, 2, 1).view(batch_size, n_channels, height, width)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, time_channels: int, has_attn: bool):\n",
    "        super().__init__()\n",
    "        self.res = ResidualBlock(in_channels, out_channels, time_channels)\n",
    "        self.attn = AttentionBlock(out_channels) if has_attn else nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        x = self.res(x, t)\n",
    "        x = self.attn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, time_channels: int, has_attn: bool):\n",
    "        super().__init__()\n",
    "        self.res = ResidualBlock(in_channels + out_channels, out_channels, time_channels)\n",
    "        self.attn = AttentionBlock(out_channels) if has_attn else nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        x = self.res(x, t)\n",
    "        x = self.attn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleBlock(Module):\n",
    "    def __init__(self, n_channels: int, time_channels: int):\n",
    "        super().__init__()\n",
    "        self.res1 = ResidualBlock(n_channels, n_channels, time_channels)\n",
    "        self.attn = AttentionBlock(n_channels)\n",
    "        self.res2 = ResidualBlock(n_channels, n_channels, time_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        x = self.res1(x, t)\n",
    "        x = self.attn(x)\n",
    "        x = self.res2(x, t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(n_channels, n_channels, (4, 4), (2, 2), (1, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        _ = t\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(n_channels, n_channels, (3, 3), (2, 2), (1, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        _ = t\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet model: UNet(\n",
      "  (image_proj): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (time_emb): TimeEmbedding(\n",
      "    (lin1): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (act): Swish()\n",
      "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (down): ModuleList(\n",
      "    (0-1): 2 x DownBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Identity()\n",
      "        (time_emb): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): Identity()\n",
      "    )\n",
      "    (2): Downsample(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (3): DownBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): Identity()\n",
      "    )\n",
      "    (4): DownBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Identity()\n",
      "        (time_emb): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): Identity()\n",
      "    )\n",
      "    (5): Downsample(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (6): DownBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): AttentionBlock(\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (projection): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (output): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (7): DownBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Identity()\n",
      "        (time_emb): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): AttentionBlock(\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (projection): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (output): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (8): Downsample(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (9): DownBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(256, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): AttentionBlock(\n",
      "        (norm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        (projection): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (output): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (10): DownBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Identity()\n",
      "        (time_emb): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): AttentionBlock(\n",
      "        (norm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        (projection): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (output): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (middle): MiddleBlock(\n",
      "    (res1): ResidualBlock(\n",
      "      (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "      (act1): Swish()\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "      (act2): Swish()\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shortcut): Identity()\n",
      "      (time_emb): Linear(in_features=256, out_features=1024, bias=True)\n",
      "      (time_act): Swish()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (attn): AttentionBlock(\n",
      "      (norm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "      (projection): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "      (output): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (res2): ResidualBlock(\n",
      "      (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "      (act1): Swish()\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "      (act2): Swish()\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shortcut): Identity()\n",
      "      (time_emb): Linear(in_features=256, out_features=1024, bias=True)\n",
      "      (time_act): Swish()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (up): ModuleList(\n",
      "    (0-1): 2 x UpBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): AttentionBlock(\n",
      "        (norm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "        (projection): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (output): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): UpBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): AttentionBlock(\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (projection): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (output): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Upsample(\n",
      "      (conv): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (4-5): 2 x UpBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): AttentionBlock(\n",
      "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (projection): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (output): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (6): UpBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): AttentionBlock(\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (projection): Linear(in_features=128, out_features=384, bias=True)\n",
      "        (output): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Upsample(\n",
      "      (conv): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (8-9): 2 x UpBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): Identity()\n",
      "    )\n",
      "    (10): UpBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): Identity()\n",
      "    )\n",
      "    (11): Upsample(\n",
      "      (conv): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (12-14): 3 x UpBlock(\n",
      "      (res): ResidualBlock(\n",
      "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (act1): Swish()\n",
      "        (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (act2): Swish()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (time_emb): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (time_act): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (attn): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "  (act): Swish()\n",
      "  (final): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Trainable parameters: 168,896,705\n",
      "Non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "class UNet(Module):\n",
    "    def __init__(self, image_channels: int = 3, \n",
    "                 n_channels: int = 64,\n",
    "                 ch_mults: Union[Tuple[int, ...], \n",
    "                                 List[int]] = (1, 2, 2, 4),\n",
    "                 is_attn: Union[Tuple[bool, ...], \n",
    "                                List[bool]] = (False, False, True, True),\n",
    "                 n_blocks: int = 2):\n",
    "        super().__init__()\n",
    "        n_resolutions = len(ch_mults)\n",
    "        self.image_proj = nn.Conv2d(image_channels, n_channels, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.time_emb = TimeEmbedding(n_channels * 4)\n",
    "        down = []\n",
    "        out_channels = in_channels = n_channels\n",
    "        for i in range(n_resolutions):\n",
    "            out_channels = in_channels * ch_mults[i]\n",
    "            for _ in range(n_blocks):\n",
    "                down.append(DownBlock(in_channels, out_channels, n_channels * 4, is_attn[i]))\n",
    "                in_channels = out_channels\n",
    "            if i < n_resolutions - 1:\n",
    "                down.append(Downsample(in_channels))\n",
    "        self.down = nn.ModuleList(down)\n",
    "        self.middle = MiddleBlock(out_channels, n_channels * 4)\n",
    "        up = []\n",
    "        in_channels = out_channels\n",
    "        for i in reversed(range(n_resolutions)):\n",
    "            out_channels = in_channels\n",
    "            for _ in range(n_blocks):\n",
    "                up.append(UpBlock(in_channels, out_channels, n_channels * 4, is_attn[i]))\n",
    "            out_channels = in_channels // ch_mults[i]\n",
    "            up.append(UpBlock(in_channels, out_channels, n_channels * 4, is_attn[i]))\n",
    "            in_channels = out_channels\n",
    "            if i > 0:\n",
    "                up.append(Upsample(in_channels))\n",
    "        self.up = nn.ModuleList(up)\n",
    "        self.norm = nn.GroupNorm(8, n_channels)\n",
    "        self.act = Swish()\n",
    "        self.final = nn.Conv2d(in_channels, image_channels, kernel_size=(3, 3), padding=(1, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        t = self.time_emb(t)\n",
    "        x = self.image_proj(x)\n",
    "        h = [x]\n",
    "        for m in self.down:\n",
    "            x = m(x, t)\n",
    "            h.append(x)\n",
    "        x = self.middle(x, t)\n",
    "        for m in self.up:\n",
    "            if isinstance(m, Upsample):\n",
    "                x = m(x, t)\n",
    "            else:\n",
    "                s = h.pop()\n",
    "                x = torch.cat((x, s), dim=1)\n",
    "                x = m(x, t)\n",
    "        return self.final(self.act(self.norm(x)))\n",
    "    \n",
    "def count_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return trainable_params, non_trainable_params\n",
    "\n",
    "model = UNet(image_channels=1).to(device=device)\n",
    "trainable, non_trainable = count_parameters(model)\n",
    "trainable, non_trainable = \"{:,}\".format(trainable), \"{:,}\".format(non_trainable)\n",
    "print(f\"Unet model: {model}\")\n",
    "print(f\"Trainable parameters: {trainable}\")\n",
    "print(f\"Non-trainable parameters: {non_trainable}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
