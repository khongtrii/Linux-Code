{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');\n",
    "</style>\n",
    "\n",
    "<div style=\"text-align: center; font-family: 'Fira Code', serif;\">\n",
    "        \n",
    "import libraries\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm.notebook import trange\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "from model import Model, count_parameters, load_model\n",
    "from part_module import cosine_schedule, forward_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');\n",
    "</style>\n",
    "\n",
    "<div style=\"text-align: center; font-family: 'Fira Code', serif;\">\n",
    "        \n",
    "init var - download file\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_url = \"https://drive.google.com/uc?id=1NhUbtDHdDKCch_ss-zNVLjSM1n9LDORk&confirm=t\"\n",
    "# out_put = \"checkpoint.pth\"\n",
    "\n",
    "# if os.path.exists(f\"./{out_put}\") == False:\n",
    "#     gdown.download(file_url, out_put, quiet=False)\n",
    "#     print(\"Download successfully !!!\")\n",
    "# else:\n",
    "#     print(\"file existed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');\n",
    "</style>\n",
    "\n",
    "<div style=\"text-align: center; font-family: 'Fira Code', serif;\">\n",
    "        \n",
    "build model\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(image_channels=1).to(device=device)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');\n",
    "</style>\n",
    "\n",
    "<div style=\"text-align: center; font-family: 'Fira Code', serif;\">\n",
    "        \n",
    "load dataset\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  32\n",
    "\n",
    "dataset = MNIST('.', train=True, transform=transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');\n",
    "</style>\n",
    "\n",
    "<div style=\"text-align: center; font-family: 'Fira Code', serif;\">\n",
    "        \n",
    "build optim - loss - ...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: max(0.2, 0.98 ** epoch))\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "t = torch.randint(0, 1000, (batch_size,), device=device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"./checkpoint.pth\"\n",
    "# check = False\n",
    "\n",
    "# load_model(url, model, optimizer, check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');\n",
    "</style>\n",
    "\n",
    "<div style=\"text-align: center; font-family: 'Fira Code', serif;\">\n",
    "        \n",
    "train our model\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 1000\n",
    "n_epochs = 100\n",
    "tqdm_epoch = trange(n_epochs)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm_epoch:\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = x.clone()\n",
    "\n",
    "        steps = torch.randint(0, timesteps, (x.shape[0], ), device=device)\n",
    "        x0 = forward_process(x, timesteps, cosine_schedule, x.shape[0], device)\n",
    "        assert not torch.isnan(x0).any(), \"x0 contains NaN!\"\n",
    "        assert not torch.isinf(x0).any(), \"x0 contains Inf!\"\n",
    "\n",
    "        y_pred = model(x0, steps)\n",
    "        loss = mse_loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    lr_current = scheduler.get_last_lr()[0]\n",
    "\n",
    "    if torch.isnan(loss) or torch.isinf(loss):\n",
    "        print(\"Loss contains NaN or Inf! Stopping training.\")\n",
    "        break\n",
    "\n",
    "    print(f\"epoch --> {epoch+1}\")\n",
    "    print(\"loss value: {:5f}, learning rate: {:.1e}\".format(loss.item(), lr_current))\n",
    "    tqdm_epoch.set_description('Loss: {:5f}'.format(loss.item()))\n",
    "\n",
    "    del loss, x0, y_pred\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, \"checkpoint_1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');\n",
    "</style>\n",
    "\n",
    "<div style=\"text-align: center; font-family: 'Fira Code', serif;\">\n",
    "        \n",
    "put model into eval and plot the prediction\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('cat.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img, (128, 128))\n",
    "img = torch.tensor(img/255., dtype=torch.float32, device=device)\n",
    "img = img.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 1000\n",
    "img_0 = forward_process(img, timesteps, cosine_schedule, img.shape[0], device)\n",
    "t = torch.randint(0, timesteps, (img_0.shape[0], ), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = model(img_0, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(img.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "ax[0].set_title(\"Real Image\")\n",
    "\n",
    "ax[1].imshow(img_0.squeeze().detach().cpu(), cmap='gray')\n",
    "ax[1].set_title(\"Noisy Image\")\n",
    "\n",
    "ax[2].imshow(y_pred.squeeze().detach().cpu(), cmap='gray')\n",
    "ax[2].set_title(\"Reconstructed Image\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
